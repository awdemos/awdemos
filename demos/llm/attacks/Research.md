- [Universal and Transferable Adversarial Attacks on Aligned Language Models] (https://arxiv.org/abs/2307.15043)


(https://github.com/llm-attacks/llm-attacks
)

# Jailbreaks

These are well known issues in the AI field and should not be terribly surprising given that LLM's token prediction procedure at this early stage of the technologies lifecycle. These attacks however demonstrate issues that can cause problems for commercial adoption of these platforms and a thorough understanding of the attacks and defenses is needed in order to build more reliable services.

(https://twitter.com/elder_plinius/status/1777817164101357744)

04-09-2024 Jailbreak GPT-4-TURBO-2024-04-09 (https://twitter.com/elder_plinius/status/1778188202664169724)

04-11-2024 Cohere Jailbreak (https://twitter.com/elder_plinius/status/1778499289498411455)


This content is shared for educational purposes only.